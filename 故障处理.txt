2019/10/24
1、ec2无法开机自启，但手动可成功开启--》环境：centos8--》检查ec2开机自启的配置文件无误，并且手动写入rc.local，也无效，随后进行测试发现centos8并不会开机执行rc.local文件，随后将ec2加入systemd管理，写配置文件，将ec2用systemd管理，并且记住selinux设置为disabled

2019/10/25：
1、windows网络有问题，更新网卡驱动 
2、s3有问题，https没关闭
3、某台物理机无法创建虚拟机：查看日志：显示cpu的ibpb指令集not found--》检查方向：cpu虚拟化--》virsh capabilities、cat /usr/share/libvirt/cpu_map.xml --》随后了解到同一批相同的物理机其他机器都正常，吧cpu_map.xml文件拷贝到有问题的虚拟机，解决完毕。--》学习了解cpu虚拟化
virsh capabilities 　　　　   #显示当前连接节点所在的宿主机和其自身的架构和特性
libvirt对CPU的定义提炼出标准的几种类型就在 cpu_map.xml文件里面查找
----》
品高云定义虚拟机cpu model为host-model，可在文件/usr/bingocloud/latest/output/vm-templete查看。
常见三种cpu model： custom、host-model、host-passthrough
custom：自己定义
host-model：默认模式，根据物理CPU的特性，选择一个最靠近的标准CPU型号
host-passthrough：直接将物理CPU暴露给虚拟机使用，在虚拟机上完全可以看到的就是物理CPU的型号
4、虚拟机出现I/O的问题。一般是检查虚拟机系统以及存储卷所在的物理存储设备--》品高上的SAN存储，都是以逻辑卷的形式。pvs，lvs，vgs，发现是多路径设备，multipath -ll查看。
5、rados存储网关（s3对象存储），使用systemdctl起服务的时候，注意要与配置文件定义的服务名称一致，否则会出现起了服务但是s3无法连接的状态

2019/10/28
1、实例迁移问题，资源是否足够，cpu指令集是否支持，通过virsh capabilities来过滤查看
2、物理机开机报cpu问题，可从升级固件，改变cpu频率p state，关闭NUMA
3、ceph报osd near full的问题，根本还是增加osd，临时可使用ceph osd df查看使用情况，然后ceph osd crush reweight osd.ID 权重 更改osd的reweight权重，将near full权重降低一点

2019/10/30
1、fio测试io，iostat磁盘监控，iftop流量监控，dstat查看所有的实时系统资源
2、重装ceph：删除原有的osd（service ceph stop osd.{id}、ceph osd crush remove osd.{id}、ceph osd rm {id}）--》删除原有的mon（ceph mon remove {id}）---》删除/var/lib/ceph/*文件---》替换ceph所有老版本的rpm包---》格式化准备磁盘---》使用脚本批量安装mon---》使用脚本安装osd---》设pg，建pool：images、instances、volumes
3、7.1系统的ceph升级到12版本后，可能会出现无法创建实例或者存储卷的问题，是rbd无法map的问题。更改map方式为rbd-nbd：更改clc.cfg文件，添加 {rbd_map_type,"rbd-nbd"}. 所有节点，刷新配置生效，7.0.29才能用。还有要加载nbd内核模块，7.0.29的完整包找到nbd.ko，放到/lib/modules/`uname -r`/kernel/block/下，执行depmod -a分析所有能使用模块。modprobe nbd加载nbd模块。

2019/10/31
1、fio测试，使用libaio引擎，iodepth=64,将io压到极限，numjobs=1，使用单线程，rw=randrw,使用随机读或者写，可直接测裸盘。
2、测顺序读写的话使用dd，挂载硬盘然后dd到文件里。不要直接dd到硬盘
3、使用SSD做RAID的话，吧缓存关闭，不然数据经过缓存不经过ssd速度反而更慢
4、迁移时，降低recovery速度，防止磁盘压力过大导致osd崩溃。osd_recovery_max_active = 3 、osd_recovery_= 0 （通过sleep的控制可以大大的降低迁移磁盘的占用，对于本身磁盘性能不太好的硬件环境下，可以用这个参数进行一下控制，能够缓解磁盘压力过大引起的osd崩溃的情况）
   eg:ceph tell osd.* injectargs "--osd_recovery_sleep 0.4"
5、ceph-mgr是mon的守护进程，主要用于管理pg map作用、当ceph-mgr发生故障，相当于整个ceph集群都会出现严重问题、建议在每个mon节点中都创建独立的ceph-mgr（至少3个ceph-mon节点 ）、只需要在每个mon节点进行创建（每个mgr需要不同的独立的命名）
6、ceph-mds是 Ceph 分布式文件系统的元数据服务器守护进程，一或多个 ceph-mds 例程协作着管理文件系统的命名空间、协调到共享 OSD 集群的访问

2019/11/1
1、更新数据库：停服务（cluster、daemon），上传新的数据包，解压进入rhel7，yum更新perconna和openssl新的数据包，替换原有的scripts文件，更改config配置，起服务。
2、重装数据库：卸载mysqlrpm包，删除配置和/opt/mysql目录，执行install.sh一键安装。前提：备份sql。将原sql导入进数据库即可。
vim config
ips=  ,
vip=
ref=
pri=1/0   0为主，1为备
sdn=0
auth=395C97A2
backup_plan=02:10
keep_backups=5

2019/11/11
1、storecli  /  megacli
2、 '/opt/bingocloud/storage使用率高，甚至达到100%'，是由于分布式存储算法自动调度控制，节点热点数据多就会占用空间大，100％后就不往该节点写入数据，不影响存储正常使用。分布式存储基本原理是将数据切片后分布到各个节点上，以提高数据安全性及读写并发性，而bingofs在其中加入了热点读写检测机制，尽可能保证读写频繁的节点上存放相应的切片数据，以降低数据的读写延时（不需要经过网络读写，牺性一定的并发性），如本地空间不能满足本地存放的条件，则分布到其他可用节点上，对性能影响小（提高了读写并发性）。
3、添加SAN存储（看实际环境灵活处理）
sh /bcshare/tools/sscanfcsan.sh        --》 扫描该接口下的SCSI磁盘设备
#!/bin/bash
devices=$(ls /sys/class/fc_host)
for i in $devices；do echo "- - -" > /sys/class/scsi_host/$i/scan；done   

sh calc_scsi_id.sh sdmf    --》 生成wwid
calc_scsi_id.sh
#!/bin/bash
device_name=$1
/lib/udev/scsi_id --whitelisted --device=/dev/$device_name

vim /etc/multipath.conf  --》  添加wwid
multipath -r    
multipath -ll | less
vgs  --》 找到物理设备sdmf对应的多路径名称
vgcreate fcsan_7k2_lun29 /dev/mapper/mpathax 
云平台添加物理存储
/opt/bingocloud/latest/output/bin/bingocloud run others sh /bcshare/tools/sscanfcsan.sh
cp /etc/multipath.conf  /bcshare/tools/multipath.conf 
/opt/bingocloud/latest/output/bin/bingocloud run others cp /bcshare/tools/multipath.conf  /etc/
/opt/bingocloud/latest/output/bin/bingocloud run others multipath -r
/opt/bingocloud/latest/output/bin/bingocloud run others "vgscan|grep lun29"

scanipsan.sh
#!/bin/bash
iscsiadm -m discovery -t st -p 10.32.249.251:3260    //发现
iscsiadm -m discovery -t st -p 10.32.249.252:3260    //发现
iscsiadm -m node -L all    //登录
iscsiadm -m session -R    //如果一个Target下新增了一个SAN资源，在服务器可以使用iscsiadm –m session –R命令刷新（rescan）已连接的iSCSI session以识别新的SAN资源：

2019/11/14
1、cat /etc/default/grub
...
GRUB_CMDLINE_LINUX="crashkernel=auto rhgb quiet intel_pstate=disable"   ##固定cpu频率
使生效：grub2-mkconfig -o /boot/grub2/grub.cfg
2、也可在此查看： cat /proc/cmdline

2019/11/18
1、使用sftp本地和远程传输文件，get下载，put上传，lcd切换本地路径
2、更新数据库时记得更新openssl，否则更新失败
3、升级云平台备份数据库，吧主库和备库都备份，最稳妥是再备份sql

2019/11/19
1、添加SAN存储（看实际环境灵活处理）
直接扫描之后就能发现多路径的，
device=ls /sys/class/fc_host
echo "- - -" > /sys/class/scsi_host/$device/scan
扫描后可出现多路径设备
multipath -ll | grep mpath 和  cat /etc/multipath.conf  | grep wwid 对比发现新添加的多路径设备
然后pvcreate  /dev/maper/mpath？
vgcreate   *****  /dev/maper/mpath?
然后云平台添加SAN存储，
/opt/bingocloud/latest/output/bin/bingocloud run others sh /bcshare/tools/scanfcsan.sh
cp /etc/multipath.conf  /bcshare/tools/multipath.conf 
/opt/bingocloud/latest/output/bin/bingocloud run others cp /bcshare/tools/multipath.conf  /etc/
/opt/bingocloud/latest/output/bin/bingocloud run others multipath -r
/opt/bingocloud/latest/output/bin/bingocloud run others “vgscan”

2、
重装云操作系统后，加入云平台，执行/opt/bingocloud/latest/output/tools/install/install_node.sh
然后注册节点，/opt/bingocloud/latest/output/bin/bingocloud register ip

2019/11/20
1、添加SAN存储，部分设备扫描完scsi设备后没有发现到多路径设备，而是出现硬盘设备，可以修改lvm配置文件
vim /etc/lvm/lvm.conf
fileter = [ “a|/dev/mapper/mpath*|”, "r|.*|" ]
配置完成后手工执行vgsan扫描一遍

以下是一些过滤设置例子：
发现所有设备，不过滤:
filter = [ “a/.*/” ]
过滤光驱设备:
filter = [ “r|/dev/cdrom|” ]
除设备名含loop的设备外过滤其他所有设备:
filter = [ “a/loop.*/”, “r/.*/” ]
除设备名含loop和hd的设备，过滤其余所有设备:
filter =[ “a|loop.*|”, “a|/dev/hd.*|”, “r|.*|” ]
只扫描/dev/hda8:
filter = [ “a|^/dev/hda8$|”, “r/.*/” ]

2、存储中心删除了lun，但物理机还有链路的记录信息，vgs会提示io block：multipath -ll mpathj 查看到分链路sd**，然后用dmsetup删除：dmsetup remove /dev/mapper/mpathj，multpath -r后正常

2019/11/21
1、ec2config的v2.0.0版本是由systemd管理的，执行完python ec2config_install.py后，需要systemctl起服务

2019/11/22
1、获取和修改pg数：ceph osd  pool  get/set   pool-name   pg_num  
                  ceph osd  pool  get/set   pool-name   pgp_num
2、导入ceph：rbd -m  xxxx   import  目标路径/   -p  pool-name   “alias”
 从ceph导出：rbd -m xxxx  export -p pool-name  镜像名称 目标路径/alias
3、降低ceph数据平衡recovery速度：ceph tell osd.* injectargs "--osd-recovery-sleep  0.5"

2019/11/25
1、RAID卡如果是没有电池的，要吧WT改为WB必须要加forced
2、ll /dev/disk/by-path/  --->  四元组的第三个数值与 megacli -ldpdinfo -a0 | grep  virtual driver： ？数值对应


2019/11/26
1、bingofs chunks missing 修复 
登陆到bingofs master主机，查找块丢失的内容：
find /bcshare -type f |xargs -i bingofscheckfile {} |grep -B1 '0 cop'
修复损坏块文件：
bingofsfilerepair /bcshare/cluster/instance/i-********/instance
2、qemu版本不一致导致热迁移失败
3、ceph状态卡住，可能是设置了策略路由导致ceph集群内部网路通信异常，可使用ss -ntp 查看是否有SYN，TIMEWAIT状态。

2019/11/27
1、更改windows密码：net user administrator XXXXX
2、重置密码：新建密钥并下载---》详情添加密钥名称---》获取密码输入密钥
3、云环境一些基本默认的配置： cat  /proc/cmdline
4、云平台需要关闭numa， numactl --hardware    
available: 1 nodes      只有一个节点说明numa已经关闭了
5、dmidecode  查看服务器硬件信息   -t

2019/12/2
1、查看管理口ipmi地址：ipmitool lan print

2019/12/3
1、tcp四次挥手断开时，当客户端最后一次回复确认关闭发送后，处在TIME_WAIT状态，会大概保持1-4分钟（防止服务端未接收到确认关闭的数据包，客户端可以重发ack）。这就导致在高并发短连接的场景下，会出现大量time_wait状态，占用端口导致正常客户端会出现无法访问，网络不通的情况。可以通过重启服务器（不推荐）释放socket连接，也可通过修改部分内核参数来优化：
vim  /etc/sysctl.conf
net.ipv4.tcp_syncookies = 1 表示开启SYN Cookies。当出现SYN等待队列溢出时，启用cookies来处理，可防范少量SYN攻击，默认为0，表示关闭；
net.ipv4.tcp_tw_reuse = 1 表示开启重用。允许将TIME-WAIT sockets重新用于新的TCP连接，默认为0，表示关闭；
net.ipv4.tcp_tw_recycle = 1 表示开启TCP连接中TIME-WAIT sockets的快速回收，默认为0，表示关闭。
net.ipv4.tcp_fin_timeout 修改系默认的 TIMEOUT 时间
sysctl -p  //生效
备注：/etc/sysctl.conf是一个允许改变正在运行中的Linux系统的接口，它包含一些TCP/IP堆栈和虚拟内存系统的高级选项，修改内核参数永久生效。
简单来说，就是打开系统的TIMEWAIT重用和快速回收。

如果以上配置调优后性能还不理想，可继续修改一下配置：
net.ipv4.tcp_keepalive_time = 1200 
#表示当keepalive起用的时候，TCP发送keepalive消息的频度。缺省是2小时，改为20分钟。
net.ipv4.ip_local_port_range = 1024 65000 
#表示用于向外连接的端口范围。缺省情况下很小：32768到61000，改为1024到65000。
net.ipv4.tcp_max_syn_backlog = 8192 
#表示SYN队列的长度，默认为1024，加大队列长度为8192，可以容纳更多等待连接的网络连接数。
net.ipv4.tcp_max_tw_buckets = 5000 
#表示系统同时保持TIME_WAIT套接字的最大数量，如果超过这个数字，TIME_WAIT套接字将立刻被清除并打印警告信息。
默认为180000，改为5000。对于Apache、Nginx等服务器，上几行的参数可以很好地减少TIME_WAIT套接字数量，但是对于 Squid，效果却不大。此项参数可以控制TIME_WAIT套接字的最大数量，避免Squid服务器被大量的TIME_WAIT套接字拖死。

2019/12/4
1、查看当前ceph配置：ceph --admin-daemon  /var/run/ceph/ceph-osd.0.asok config show
2、在线修改当前ceph配置：ceph tell osd.* injectargs “--参数  数值”
3、集群出现Slow Request告警：客户端发起写请求，待访问对象在一个或者多个副本处在降级状态。
对于客户端发起写请求，必须要求修复该对象的所有降级副本后才能继续处理写请求，当请求进来，触发降级对象强制执行同步修复很容易导致客户端读写请求时延显著变长，进而导致集群出现slow request告警。

2019/12/5
1、
#测试文件，可直接测裸盘
filename=
#随机读randread，随机写randwrite，随机读写randrw
rw=randread
#单次io块文件大小
bs=4k
#io引擎
ioengine=libaio
#跳过缓存
direct=1
#测试深度，将io压到极限
iodepth=64
#单线程
numjobs=1
#测试时长，不定义则每次4k直到吧文件写完为止
runtime=
2、fio和dd
 随机写：
 ①、fio -name=asd -filename=/dev/vdb -bs=4k -runtime=180 -iodepth=64 -numjobs=1 -direct=1 -ioengine=libaio rw=randwrite 
 write: io=316828KB, bw=1757.8KB/s, iops=439, runt=180252mse
 ②、mount /dev/vdb /test ----》  time dd if=/dev/zero of=/test/test1.file bs=4M count=100  oflag=direct
 419430400 bytes (419 MB) copied, 22.2305 s, 18.9 MB/s
 随机读：
 ①、fio -name=asd -filename=/dev/vdb -bs=4k -runtime=180 -iodepth=64 -numjobs=1 -direct=1 -ioengine=libaio -rw=randread
 read : io=2703.7MB, bw=15350KB/s, iops=3837, runt=180358msec
 ②、time dd if=/dev/vdb of=/dev/null  bs=4M count=1000  iflag=direct
 4194304000 bytes (4.2 GB) copied, 105.86 s, 39.6 MB/s
 3、升级openssh
 
 2019/12/6
1、rhel6.5升级mysql到5.6.45
1）、安装percona软件包时报错，与原percona软件包冲突，可用rpm -e --nodeps 卸载后，装要安装的软件包
2）、将新的scripts拷贝
3）、更改配置文件config 
vim config
ips=  ,
vip=
ref=
pri=1/0   0为主，1为备
sdn=0
auth=395C97A2
backup_plan=02:10
keep_backups=5

2、重装数据库
1）安装软件包
2）执行install.sh
3）停服务，拷贝data和my.cnf过来
4）删除data目录里面ib_logfile*（否则会报错）
5）启动


2019/12/9
1、 1 osds exist in the crush map but not in the osdmap  少做了第三步
systemctl stop ceph-osd@38.serivce
ceph osd out 38
ceph osd crush remove osd.38
ceph osd rm 38
2、物理磁盘定位：
# /opt/MegaRAID/MegaCli/MegaCli64 -pdlocate -start -physdrv[64:2] -a0 # 让slot 2的硬盘灯闪烁
# /opt/MegaRAID/MegaCli/MegaCli64 -pdlocate -stop -physdrv[64:2] -a0 # 停止闪烁

2019/12/10
1、ceph出现 HEALTH_ERR 1 scrub errors; Possible data damage: 1 pg inconsistent 
1）ceph health detail      查看详细信息
2）ceph osd find      找出pg异常所在osd的节点
3）systemctl stop ceph-osd@xx     停止该osd
4）ceph-osd -i xx --flush-jounal      冲洗journal
5）systemctl start ceph-osd@xx               
5）ceph pg repair xxxx          重启后等几分钟没反应后再执行修复

2、top命令
%Cpu(s): 58.3 us, 40.7 sy,  0.0 ni,  0.0 id,  0.1 wa,  0.0 hi,  0.9 si,  0.0 st
 us — 用户空间占用CPU的百分比。
 sy — 内核空间占用CPU的百分比。
 ni — 改变过优先级的进程占用CPU的百分比
 id — 空闲CPU百分比
 wa — IO等待占用CPU的百分比
 hi — 硬中断（Hardware IRQ）占用CPU的百分比
 si — 软中断（Software Interrupts）占用CPU的百分比

3、
# 查看物理CPU个数
[root@AAA ~]# cat /proc/cpuinfo| grep "physical id"| sort| uniq| wc -l

# 查看每个物理CPU中core的个数(即核数)
[root@AAA ~]# cat /proc/cpuinfo| grep "cpu cores"| uniq

# 查看逻辑CPU的个数
[root@AAA ~]# cat /proc/cpuinfo| grep "processor"| wc -l

系统负载uptime不要超过processor的值！！


2019/12/11
1、
virsh list 
virsh domblklist xx

2019/12/13
1、strings命令 在对象文件或二进制文件中查找可打印的字符串。字符串是4个或更多可打印字符的任意序列，以换行符或空字符结束。 strings命令对识别随机对象文件很有用。（实现对二进制文件的搜索）

2、
更改openssh版本号：（例如由7.9p1修改为8.1p1）
whereis sshd  
strings /usr/sbin/sshd  |  grep OpenSSH
cp /usr/sbin/sshd /usr/sbin/sshd.bak
sed -i 's/OpenSSH_7.9p1/OpenSSH_8.1p1/g' /usr/sbin/sshd
/etc/init.d/sshd restart
###如果更改失败，则继续更改下面：（遇到过之前更改过版本号，升级后不显示新的版本号的情况需要修改下面配置文件）
which  ssh
strings /usr/local/openssh/bin/ssh | grep OpenSSH
cp /usr/local/openssh/bin/ssh /usr/local/openssh/bin/ssh.bak
sed -i 's/OpenSSH_7.9p1/OpenSSH_8.1p1/g' /usr/local/openssh/bin/ssh

更改openssl版本号：(例如由1.0.2k修改为1.0.1e)
which openssl
ldd /usr/local/openssl/bin/openssl | grep libcryp   （libcrypto为存放openssl版本号的库）
   libcrypto.so.1.0.0 => /usr/local/openssl/lib/libcrypto.so.1.0.0 (0x00007feb28aa4000)
strings  /usr/local/openssl/lib/libcrypto.so.1.0.0 | grep 1.0.2k
cp /usr/local/openssl/lib/libcrypto.so.1.0.0 /usr/local/openssl/lib/libcrypto.so.1.0.0.bak
sed -i 's/1.0.2k/1.0.1e/g' /usr/local/openssl/lib/libcrypto.so.1.0.0
/etc/init.d/sshd restart

3、
whereis
whereis命令只能用于程序名的搜索，而且只搜索二进制文件（参数-b）、man说明文件（参数-m）和源代码文件（参数-s）。如果省略参数，则返回所有信息。

which
which命令的作用是，在PATH变量指定的路径中，搜索某个系统命令的位置，并且返回第一个搜索结果。也就是说，使用which命令，就可以看到某个系统命令是否存在，以及执行的到底是哪一个位置的命令。

 4、
 ldd命令：查看程序需要依赖什么库 

2019/12/16
1、
日志盘损坏
1)更换日志盘，修改journal链接
2)重建日志系统
ceph-osd --mkjournal -i {id}

数据盘损坏
1)更换数据盘，格式化，建立journal
2)获取osd-uuid
ceph osd dump|grep osd.{id}
3)重建数据系统
ceph-osd -i {id} --mkfs --osd-uuid {osd-uuid}

例如：
ceph更换硬盘：
更换硬盘后：
一、使用MegaCLi命令，megacli -pdlist -a0 | less  ,找到firmware stat状态是还没做raid的硬盘，记住enclosure device id:slot number 。 使用命令做对应的raid
二、做完raid，观察输出的virtual driver：？ 的值，然后使用命令 ll /dev/disk/by-path，一般在四元组<host:channel:id:lun>，id的值会与之对应，然后观察对应的是哪块硬盘。然后格式化该硬盘。
三、然后挂载ceph的对应的osd目录到该硬盘，查看隔壁的目录，使用realpath看它的journal盘所对应的实际硬盘，猜测本jounal所对应的硬盘，使用 ceph osd dump|grep osd.? ，观察最后的uuid，然后使用命令 dd if=/dev/??? bs=1 count=512 | hexdump -C 打印该硬盘的十六进制信息，查看和osd dump出来的uuid是否一致，如果一致则该硬盘就是这个osd的journal盘，然后ll /dev/disk/by-partuuid | grep “刚刚查找到的journal盘”，进入osd挂载目录，建立journal软链接，ln -s /dev/disk/by-partuuid/XXXXXX  journal
四、清除原journal盘的头部信息，一般清200M,dd if=/dev/zero of=/dev/XXX bs=1M count=512.执行这一步前可使用iostat命令查看该硬盘是否有在使用
五、重建数据系统： ceph-osd -i {id} --mkfs --osd-uuid {osd-uuid}
六、设置开机自动挂载


2019/12/17
1、
1、mon起不来，终极办法：
rm -rf /var/lib/ceph/mon/ceph-0/*
2、去正常mon节点导出monmap
1）服务运行时
ceph mon getmap -o /tmp/monmap
2）服务停止时
ceph-mon -i {id} --extract-monmap /tmp/monmap
3、创建monitor文件系统
ceph-mon -i {id} --mkfs --monmap {monmap}
4、chown  -RH ceph:ceph /var/lib/ceph/mon/ceph-0/
5、systemctl start ceph-mon@0

2、
华为管理口默认密码： Huawei12#$

3、
集群掉电导致无法正常启动，很可能是文件系统损坏，开机运行rc.local或者/etc/fstab出问题
1）挂载镜像进入救援模式，在救援模式里面将/etc/rc.local,,,/etc/fstab注释，开机仍然失败的话，直接修复系统盘，重启
2）在启动界面按c也可进入救援模式
3）（骚操作）若没有镜像，可在启动界面按e ，进行编辑，将只读 ro改为 rw，，再加上init=/mnt/sysimage/bin/bash，可进行上述操作，但不能修复文件系统
4）mount -l查看文件系统挂载有无问题，如有问题，可使用xfs_repair /dev/*** 进行修复
5）xfs_repair修复失败，可先执行xfs_repair -L /dev/*** 清空日志，再进行修复
6）修复成功后记得恢复挂载和恢复启动rc.local得服务
7）进入救援模式后，可对vda进行parted print，如果是标准分区可使用xfs_repair,如果是lvm ，可先lvscan ，再使用xfs_repair修复根目录对应的路径

2019/12/18
1、ceph osd  perf     #主要解决单块磁盘问题，如果有问题应及时剔除osd。统计的是平均值。。如果出现io线程出现超时，可查看是否是osd磁盘性能出现了瓶颈。。可以结合Megacli查看磁盘是否有坏道

2019/19/19
1、没有raid卡的话，检查是否有sas控制器，有的话下载sas工具：https://www.broadcom.com/products/storage/host-bus-adapters/sas-9311-8i#downloads
sas3ircu   
ll  /dev/disk/by-id  | grep   sdd1   
例如输出如下：
lrwxrwxrwx 1 root root 9 8月 1 14:14 ata-ST8000NM0055-1RM112_ZA1CNVDK -> ../../sdd1
lrwxrwxrwx 1 root root 9 8月 1 14:14 lvm-pv-uuid-J1WyJ6-4VkN-BPwC-Qcab-eUwZ-RfY1-Cq8x66 -> ../../sdd1
定位：
sas3ircu 0 display | grep -i ZA1CNVDK   -A 3 -B 8  
点亮：
sas3ircu  0  locate  E：S   on
关闭：
sas3ircu  0  locate  E：S   on


2019/12/20
1、windows修复磁盘：   cmd   ---》  chkdsk  盘符：  /f  


2019/12/23
1、执行vgs或者pvs出现如下大量warning时，是/etc/lvm/lvm.conf没有做过滤条件：
例如：fileter = [ “a|/dev/mapper/mpath*|”, "r|.*|" ]    只允许多路径pv名为mpath*的，拒绝所有
WARNING: PV jFToQp-04Ir-0LC4-czPm-f9P2-KANW-5ri19Z prefers device /dev/mapper/fcsan_7k2_lun06-i--F247956A.instance5 because device was seen first.
WARNING: PV IkE2Ap-fCzY-lM4O-i8SA-M0sM-hzKZ-R5rZB0 on /dev/mapper/fcsan_7k2_lun05-i--BA23D806.instance2 was already found on /dev/mapper/fcsan_7k2_lun05-i--6BC57BF5.instance2.
 
2、数据库修改实例状态： bingocloud---》instance
 select instanceStatus from instance where instanceID="***";
 update instance set instanceStatus="****" where instanceID="***"
备注：
运行中：running
已销毁：terminated
已关机：stopped
销毁中：shutting-down  （不正常）

3、
dmsetup ls

4、
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!开启用户命令审计!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
在/etc/bashrc文件末尾添加如下：
export PROMPT_COMMAND='{ Cmd=$(history 1 | { read x y; echo $y; }); logger -p local5.info "$HOSTNAME [HIST] : $SSH_CLIENT : $PWD : $Cmd"; }'

在/etc/rsyslog.conf文件修改以下内容：将
*.info;mail.none;authpriv.none;cron.none         /var/log/messages
修改为
*.info;mail.none;authpriv.none;cron.none;local5.none                /var/log/messages
添加以下内容：
local5.*    /var/log/commands


2019/12/24
1、kpartx挂载虚拟文件系统
kpartx -av  ****
kpartx -d   
kpartx -a指定去添加哪个映像文件(add)，-v是指挂到loop设备(verbose)，-d就是delete的意思
使用完镜像文件系统后退出，先使用umount 卸载，其次使用 kpartx  -dv /dev/loop0 ，最后使用losetup -d /dev/loop0断掉和映像文件的挂接关系。

例如：
[root@localhost ~]# losetup -f                    #查看哪个loop设备是空闲的 
[root@localhost ~]# losetup /dev/loop2 rjk.raw    #连接
[root@localhost ~]# kpartx -av /dev/loop2            #挂载虚拟文件系统，也可以先对/dev/loop2分区，
[root@localhost ~]# mount /dev/mapper/loop2p2 /media #挂载
[root@localhost ~]# umount /media                      #结束后umount卸载操作
[root@localhost ~]# kpartx -dv /dev/mapper/loop2p2 

2、
Linux losetup命令用于设置循环设备。
循环设备可把文件虚拟成区块设备，籍以模拟整个文件系统，让用户得以将其视为硬盘驱动器，光驱或软驱等设备，并挂入当作目录来使用。

# mkdir /mnt/loopback
# mount -o loop loopfile.img /mnt/loopback
mount 命令的 -o loop 选项可以将任意一个 loopback 文件系统挂载。

上面的 mount 命令实际等价于下面两条命令：

# losetup /dev/loop0 loopfile.img
# mount /dev/loop0 /mnt/loopback
因此实际上，mount -o loop 在内部已经默认的将文件和 /dev/loop0 挂载起来了。

然而对于第一种方法(mount -o loop)并不能适用于所有的场景。比如，我们想创建一个硬盘文件，然后对该文件进行分区，接着挂载其中一个子分区，这时就不能用 -o loop 这种方法了。因此必须如下做：

# losetup /dev/loop1 loopfile.img
# fdisk /dev/loop1


2019/12/25
1、fcsan出问题：
1）查看光纤口是否是online。cat /sys/class/fc_host/host15/port_state   （如果是linkdown，联系客户检查端口）
2）扫描：device=ls /sys/class/fc_host 
        echo "- - -" > /sys/class/scsi_host/$device/scan
3）光纤通道出现问题。检查光纤交换机

2、strace  执行命令卡住，可使用该命令跟踪
例如： strace df -h

3、日志出现类似以下报错：是qemu和libvirt版本不匹配。可进行升级
$su_do timeout 30 virsh create /opt/bingocloud/run/instance/i-6759B247/libvirt.xml
error: Failed to create domain from /opt/bingocloud/run/instance/i-6759B247/libvirt.xml

$su_do timeout 30 virsh create /opt/bingocloud/run/instance/i-AF66E5C4/libvirt.xml
error: failed to connect to the hypervisor
error: Failed to connect socket to '/var/run/libvirt/libvirt-sock': No such file or directory

2019/12/26
1、建密钥显示服务异常，可能是版本太低（比如v6），升级了openssl，需要打补丁：
1）将补丁包解压到/opt/bingocloud/latest/目录下
2）执行/opt/bingocloud/latest/ouput/bin/bingocloud client 
util:nl(clc_create_key_pair).
q().

2、备云控无法通过web访问，服务和端口一切正常，可能是时间同步问题

2019/12/30
1、bingofs  chunks missing修复：（如果有上千的话，要确定是否所有节点都加进来了,,不要轻易修复，否则数据彻底丢失，，，或者先备份所有元数据）

find /bcshare -type f |xargs -i bingofscheckfile {} |grep -B1 '0 cop'

bingofsfilerepair /bcshare/cluster/instance/i-********/instance

2、bingofs  断电恢复数据：（注意做任何操作前先备份元数据！！！！！！！！！！！！！！）
断电导致master无法启动，在master使用 ：   bingofsmetarestore -a 
或者：   bingofsmetarestore  -m  metadata.bfs.back  -o   metadata.bfs   /var/bingofs/changelog.*.bfs
再重启bingofsmster
备注：主要元数据文件metadata.bfs在master运行时 会被命名为metadata.bfs.bak

3、






