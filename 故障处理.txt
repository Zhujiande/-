2019/10/24
1、ec2无法开机自启，但手动可成功开启--》环境：centos8--》检查ec2开机自启的配置文件无误，并且手动写入rc.local，也无效，随后进行测试发现centos8并不会开机执行rc.local文件，随后将ec2加入systemd管理，写配置文件，将ec2用systemd管理，并且记住selinux设置为disabled

2019/10/25：
1、windows网络有问题，更新网卡驱动
2、s3有问题，https没关闭
3、某台物理机无法创建虚拟机：查看日志：显示cpu的ibpb指令集not found--》检查方向：cpu虚拟化--》virsh capabilities、cat /usr/share/libvirt/cpu_map.xml --》随后了解到同一批相同的物理机其他机器都正常，吧cpu_map.xml文件拷贝到有问题的虚拟机，解决完毕。--》学习了解cpu虚拟化
virsh capabilities 　　　　   #显示当前连接节点所在的宿主机和其自身的架构和特性
libvirt对CPU的定义提炼出标准的几种类型就在 cpu_map.xml文件里面查找
----》
品高云定义虚拟机cpu model为host-model，可在文件/usr/bingocloud/latest/output/vm-templete查看。
常见三种cpu model： custom、host-model、host-passthrough
custom：自己定义
host-model：默认模式，根据物理CPU的特性，选择一个最靠近的标准CPU型号
host-passthrough：直接将物理CPU暴露给虚拟机使用，在虚拟机上完全可以看到的就是物理CPU的型号
4、虚拟机出现I/O的问题。一般是检查虚拟机系统以及存储卷所在的物理存储设备--》品高上的SAN存储，都是以逻辑卷的形式。pvs，lvs，vgs，发现是多路径设备，multipath -ll查看。
5、rados存储网关（s3对象存储），使用systemdctl起服务的时候，注意要与配置文件定义的服务名称一致，否则会出现起了服务但是s3无法连接的状态

2019/10/28
1、实例迁移问题，资源是否足够，cpu指令集是否支持，通过virsh capabilities来过滤查看
2、物理机开机报cpu问题，可从升级固件，改变cpu频率p state，或者修改NUMA
3、ceph报osd near full的问题，根本还是增加osd，临时可使用ceph osd df查看使用情况，然后ceph osd crush reweight osd.ID 权重 更改osd的reweight权重，将near full权重降低一点

2019/10/30
1、fio测试io，iostat磁盘监控，iftop流量监控，dstat查看所有的实时系统资源
2、重装ceph：删除原有的osd（service ceph stop osd.{id}、ceph osd crush remove osd.{id}、ceph osd rm {id}）--》删除原有的mon（ceph mon remove {id}）---》删除/var/lib/ceph/*文件---》替换ceph所有老版本的rpm包---》格式化准备磁盘---》使用脚本批量安装mon---》使用脚本安装osd---》设pg，建pool：images、instances、volumes
3、7.1系统的ceph升级到12版本后，可能会出现无法创建实例或者存储卷的问题，是rbd无法map的问题。更改map方式为rbd-nbd：更改clc.cfg文件，添加 {rbd_map_type,"rbd-nbd"}. 所有节点，刷新配置生效，7.0.29才能用。还有要加载nbd内核模块，7.0.29的完整包找到nbd.ko，放到/lib/modules/`uname -r`/kernel/block/下，执行depmod -a分析所有能使用模块。modprobe nbd加载nbd模块。

2019/10/31
1、fio测试，使用libaio引擎，iodepth=64,将io压到极限，numjobs=1，使用单线程，rw=randrw,使用随机读或者写，可直接测裸盘。
2、测顺序读写的话使用dd，挂载硬盘然后dd到文件里。不要直接dd到硬盘
3、使用SSD做RAID的话，吧缓存关闭，不然数据经过缓存不经过ssd速度反而更慢
4、迁移时，降低recovery速度，防止磁盘压力过大导致osd崩溃。osd_recovery_max_active = 3 、osd_recovery_sleep = 0 （通过sleep的控制可以大大的降低迁移磁盘的占用，对于本身磁盘性能不太好的硬件环境下，可以用这个参数进行一下控制，能够缓解磁盘压力过大引起的osd崩溃的情况）
   eg:ceph tell osd.* injectargs "--osd_recovery_sleep 0.4"
5、ceph-mgr是mon的守护进程，主要用于管理pg map作用、当ceph-mgr发生故障，相当于整个ceph集群都会出现严重问题、建议在每个mon节点中都创建独立的ceph-mgr（至少3个ceph-mon节点 ）、只需要在每个mon节点进行创建（每个mgr需要不同的独立的命名）
6、ceph-mds是 Ceph 分布式文件系统的元数据服务器守护进程，一或多个 ceph-mds 例程协作着管理文件系统的命名空间、协调到共享 OSD 集群的访问

2019/11/1
1、更新数据库：停服务（cluster、daemon），上传新的数据包，解压进入rhel7，yum更新perconna和openssl新的数据包，替换原有的scripts文件，更改config配置，起服务。
2、重装数据库：卸载mysqlrpm包，删除配置和/opt/mysql目录，执行install.sh一键安装。前提：备份sql。将原sql导入进数据库即可。
vim config
ips=  ,
vip=
ref=
pri=1/0   0为主，1为备
sdn=0
auth=395C97A2
backup_plan=02:10
keep_backups=5

2019/11/11
1、storecli  /  megacli
2、 '/opt/bingocloud/storage使用率高，甚至达到100%'，是由于分布式存储算法自动调度控制，节点热点数据多就会占用空间大，100％后就不往该节点写入数据，不影响存储正常使用。分布式存储基本原理是将数据切片后分布到各个节点上，以提高数据安全性及读写并发性，而bingofs在其中加入了热点读写检测机制，尽可能保证读写频繁的节点上存放相应的切片数据，以降低数据的读写延时（不需要经过网络读写，牺性一定的并发性），如本地空间不能满足本地存放的条件，则分布到其他可用节点上，对性能影响小（提高了读写并发性）。
3、添加SAN存储（看实际环境灵活处理）
sh /bcshare/tools/sscanfcsan.sh        --》 扫描该接口下的SCSI磁盘设备
#!/bin/bash
devices=$(ls /sys/class/fc_host)
for i in $devices；do echo "- - -" > /sys/class/scsi_host/$i/scan；done   

sh calc_scsi_id.sh sdmf    --》 生成wwid
calc_scsi_id.sh
#!/bin/bash
device_name=$1
/lib/udev/scsi_id --whitelisted --device=/dev/$device_name

vim /etc/multipath.conf  --》  添加wwid
multipath -r    
multipath -ll | less
vgs  --》 找到物理设备sdmf对应的多路径名称
vgcreate fcsan_7k2_lun29 /dev/mapper/mpathax 
云平台添加物理存储
/opt/bingocloud/latest/output/bin/bingocloud run others sh /bcshare/tools/sscanfcsan.sh
cp /etc/multipath.conf  /bcshare/tools/multipath.conf 
/opt/bingocloud/latest/output/bin/bingocloud run others cp /bcshare/tools/multipath.conf  /etc/
/opt/bingocloud/latest/output/bin/bingocloud run others multipath -r
/opt/bingocloud/latest/output/bin/bingocloud run others "vgscan|grep lun29"

scanipsan.sh
#!/bin/bash
iscsiadm -m discovery -t st -p 10.32.249.251:3260    //发现
iscsiadm -m discovery -t st -p 10.32.249.252:3260    //发现
iscsiadm -m node -L all    //登录
iscsiadm -m session -R    //如果一个Target下新增了一个SAN资源，在服务器可以使用iscsiadm –m session –R命令刷新（rescan）已连接的iSCSI session以识别新的SAN资源：

2019/11/14
1、cat /etc/default/grub
...
GRUB_CMDLINE_LINUX="crashkernel=auto rhgb quiet intel_pstate=disable"   ##固定cpu频率
使生效：grub2-mkconfig -o /boot/grub2/grub.cfg
2、也可在此查看： cat /proc/cmdline

2019/11/18
1、使用sftp本地和远程传输文件，get下载，put上传，lcd切换本地路径
2、更新数据库时记得更新openssl，否则更新失败
3、升级云平台备份数据库，吧主库和备库都备份，最稳妥是再备份sql

2019/11/19
1、添加SAN存储（看实际环境灵活处理）
直接扫描之后就能发现多路径的，
device=ls /sys/class/fc_host
echo "- - -" > /sys/class/scsi_host/$device/scan
扫描后可出现多路径设备
multipath -ll | grep mpath 和  cat /etc/multipath.conf  | grep wwid 对比发现新添加的多路径设备
然后pvcreate  /dev/maper/mpath？
vgcreate   *****  /dev/maper/mpath?
然后云平台添加SAN存储，
/opt/bingocloud/latest/output/bin/bingocloud run others sh /bcshare/tools/scanfcsan.sh
cp /etc/multipath.conf  /bcshare/tools/multipath.conf 
/opt/bingocloud/latest/output/bin/bingocloud run others cp /bcshare/tools/multipath.conf  /etc/
/opt/bingocloud/latest/output/bin/bingocloud run others multipath -r
/opt/bingocloud/latest/output/bin/bingocloud run others “vgscan”

2、
重装云操作系统后，加入云平台，执行/opt/bingocloud/latest/output/tools/install/install_node.sh
然后注册节点，/opt/bingocloud/latest/output/bin/bingocloud register ip

2019/11/20
1、添加SAN存储，部分设备扫描完scsi设备后没有发现到多路径设备，而是出现硬盘设备，可以修改lvm配置文件
vim /etc/lvm/lvm.conf
fileter = [ “a|/dev/mapper/mpath*|”, "r|.*|" ]
配置完成后手工执行vgsan扫描一遍

以下是一些过滤设置例子：
发现所有设备，不过滤:
filter = [ “a/.*/” ]
过滤光驱设备:
filter = [ “r|/dev/cdrom|” ]
除设备名含loop的设备外过滤其他所有设备:
filter = [ “a/loop.*/”, “r/.*/” ]
除设备名含loop和hd的设备，过滤其余所有设备:
filter =[ “a|loop.*|”, “a|/dev/hd.*|”, “r|.*|” ]
只扫描/dev/hda8:
filter = [ “a|^/dev/hda8$|”, “r/.*/” ]

2、存储中心删除了lun，但物理机还有链路的记录信息，vgs会提示io block：multipath -ll mpathj 查看到分链路sd**，然后用dmsetup删除：dmsetup remove /dev/mapper/mpathj，multpath -r后正常

2019/11/21
1、ec2config的v2.0.0版本是由systemd管理的，执行完python ec2config_install.py后，需要systemctl起服务

2019/11/22
1、获取和修改pg数：ceph osd  pool  get/set   pool-name   pg_num  
                  ceph osd  pool  get/set   pool-name   pgp_num
2、导入ceph：rbd -m  xxxx   import  目标路径/   -p  pool-name   “alias”
 从ceph导出：rbd -m xxxx  export -p pool-name  镜像名称 目标路径/alias
3、降低ceph数据平衡recovery速度：ceph tell osd.* injectargs "--osd-recovery-sleep  0.5"

2019/11/25
1、RAID卡如果是没有电池的，要吧WT改为WB必须要加forced
2、ll /dev/disk/by-path/  --->  四元组的第三个数值与 megacli -ldpdinfo -a0 | grep  virtual driver： ？数值对应


2019/11/26
1、bingofs chunks missing 修复 
登陆到bingofs master主机，查找块丢失的内容：
find /bcshare -type f |xargs -i bingofscheckfile {} |grep -B1 '0 cop'
修复损坏块文件：
bingofsfilerepair /bcshare/cluster/instance/i-********/instance
2、qemu版本不一致导致热迁移失败
3、ceph状态卡住，可能是设置了策略路由导致ceph集群内部网路通信异常，可使用ss -ntp 查看是否有SYN，TIMEWAIT状态。

2019/11/27
1、更改windows密码：net user administrator XXXXX
2、重置密码：新建密钥并下载---》详情添加密钥名称---》获取密码输入密钥
3、云环境一些基本默认的配置： cat  /proc/cmdline
4、云平台需要关闭numa， numactl --hardware    
available: 1 nodes      只有一个节点说明numa已经关闭了
5、dmidecode  查看服务器硬件信息   -t

2019/12/2
1、查看管理口ipmi地址：ipmitool lan print

2019/12/3
1、tcp四次挥手断开时，当客户端最后一次回复确认关闭发送后，处在TIME_WAIT状态，会大概保持1-4分钟（防止服务端未接收到确认关闭的数据包，客户端可以重发ack）。这就导致在高并发短连接的场景下，会出现大量time_wait状态，占用端口导致正常客户端会出现无法访问，网络不通的情况。可以通过重启服务器（不推荐）释放socket连接，也可通过修改部分内核参数来优化：
vim  /etc/sysctl.conf
net.ipv4.tcp_syncookies = 1 表示开启SYN Cookies。当出现SYN等待队列溢出时，启用cookies来处理，可防范少量SYN攻击，默认为0，表示关闭；
net.ipv4.tcp_tw_reuse = 1 表示开启重用。允许将TIME-WAIT sockets重新用于新的TCP连接，默认为0，表示关闭；
net.ipv4.tcp_tw_recycle = 1 表示开启TCP连接中TIME-WAIT sockets的快速回收，默认为0，表示关闭。
net.ipv4.tcp_fin_timeout 修改系默认的 TIMEOUT 时间
sysctl -p  //生效
备注：/etc/sysctl.conf是一个允许改变正在运行中的Linux系统的接口，它包含一些TCP/IP堆栈和虚拟内存系统的高级选项，修改内核参数永久生效。
简单来说，就是打开系统的TIMEWAIT重用和快速回收。

如果以上配置调优后性能还不理想，可继续修改一下配置：
net.ipv4.tcp_keepalive_time = 1200 
#表示当keepalive起用的时候，TCP发送keepalive消息的频度。缺省是2小时，改为20分钟。
net.ipv4.ip_local_port_range = 1024 65000 
#表示用于向外连接的端口范围。缺省情况下很小：32768到61000，改为1024到65000。
net.ipv4.tcp_max_syn_backlog = 8192 
#表示SYN队列的长度，默认为1024，加大队列长度为8192，可以容纳更多等待连接的网络连接数。
net.ipv4.tcp_max_tw_buckets = 5000 
#表示系统同时保持TIME_WAIT套接字的最大数量，如果超过这个数字，TIME_WAIT套接字将立刻被清除并打印警告信息。
默认为180000，改为5000。对于Apache、Nginx等服务器，上几行的参数可以很好地减少TIME_WAIT套接字数量，但是对于 Squid，效果却不大。此项参数可以控制TIME_WAIT套接字的最大数量，避免Squid服务器被大量的TIME_WAIT套接字拖死。

2019/12/4
1、查看当前ceph配置：ceph --admin-daemon  /var/run/ceph/ceph-osd.0.asok config show
2、在线修改当前ceph配置：ceph tell osd.* injectargs “--参数  数值”
3、集群出现Slow Request告警：客户端发起写请求，待访问对象在一个或者多个副本处在降级状态。
对于客户端发起写请求，必须要求修复该对象的所有降级副本后才能继续处理写请求，当请求进来，触发降级对象强制执行同步修复很容易导致客户端读写请求时延显著变长，进而导致集群出现slow request告警。

2019/12/5
1、
#测试文件，可直接测裸盘
filename=
#随机读randread，随机写randwrite，随机读写randrw
rw=randread
#单次io块文件大小
bs=4k
#io引擎
ioengine=libaio
#跳过缓存
direct=1
#测试深度，将io压到极限
iodepth=64
#单线程
numjobs=1
#测试时长，不定义则每次4k直到吧文件写完为止
runtime=
2、fio和dd
 随机写：
 ①、fio -name=asd -filename=/dev/vdb -bs=4k -runtime=180 -iodepth=64 -numjobs=1 -direct=1 -ioengine=libaio rw=randwrite 
 write: io=316828KB, bw=1757.8KB/s, iops=439, runt=180252mse
 ②、mount /dev/vdb /test ----》  time dd if=/dev/zero of=/test/test1.file bs=4M count=100  oflag=direct
 419430400 bytes (419 MB) copied, 22.2305 s, 18.9 MB/s
 随机读：
 ①、fio -name=asd -filename=/dev/vdb -bs=4k -runtime=180 -iodepth=64 -numjobs=1 -direct=1 -ioengine=libaio -rw=randread
 read : io=2703.7MB, bw=15350KB/s, iops=3837, runt=180358msec
 ②、time dd if=/dev/vdb of=/dev/null  bs=4M count=1000  iflag=direct
 4194304000 bytes (4.2 GB) copied, 105.86 s, 39.6 MB/s
 3、升级openssh
 
 
 
 
 
 
 







